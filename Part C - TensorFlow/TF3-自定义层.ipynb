{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 3 - 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 没有权重的层\n",
    "\n",
    "* 某些层没有权重，如 keras.layers.Flatten, keras.layers.ReLU。\n",
    "* 若要编写不带权重的自定义层，最简单的方法是编写一个函数包装在 keras.layers.Lambda 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 自定义层可以用在激活函数中（activation=tf.exp, activation=keras.activations.exponential, activation='exponential'）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7563 - val_loss: 0.4097\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4338 - val_loss: 0.3685\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.3524\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.3446\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.3425\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36374431848526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 带权重的层（有状态层）\n",
    "\n",
    "* 需要创建 keras.layers.Layer 类的子类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs) # 负责处理 input_shape, trainable, name 等参数\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation) # 将 activation 转换为标准的激活函数\n",
    "        \n",
    "    def build(self, batch_input_shape): # 首次使用该层的时候将调用，batch_input_shape 是由keras自动传给他的。\n",
    "        # 创建层的变量\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units], initializer='zeros')\n",
    "        super().build(batch_input_shape) # 调用父类的方法，告诉 keras 这一层被构建了。\n",
    "        \n",
    "    def call(self, X): # 执行所需的操作\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape): # 可以不给出 P346\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units]) # 最后一个维度被替换为神经元的数量\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units': self.units,\n",
    "                'activation': keras.activations.serialize(self.activation)} # 保存激活函数的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.3395 - val_loss: 1.4438\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5480 - val_loss: 0.4536\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4679130017757416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation='relu', input_shape=input_shape),\n",
    "    MyDense(1),\n",
    "])\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/TF3-model1.h5')\n",
    "model = keras.models.load_model('./models/TF3-model1.h5',\n",
    "                                custom_objects={'MyDense': MyDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 多输入层的创建\n",
    "\n",
    "* 如 Concatenate 层。\n",
    "* call 方法的参数应包含所有输入的元组，返回输出列表；\n",
    "* compute_output_shape 方法应该是一个包含每个输入形状的元组，返回输出形状的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print('X1.Shape: ', X1.shape, 'X2.shape: ', X2.shape)\n",
    "        return X1 + X2, X1 * X2 # 将两个输入返回加和乘。\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.Shape:  (None, 2) X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# 注意不能用顺序API，因为有多个输入多个输出。\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_multi_layer_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "X1.Shape:  (11610, 4) X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.Shape:  (None, 4) X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.Shape:  (None, 4) X2.shape:  (None, 4)\n",
      "X1.Shape:  (None, 4) X2.shape:  (None, 4)\n",
      "353/363 [============================>.] - ETA: 0s - loss: 1.8828X1.Shape:  (None, 4) X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.8560 - val_loss: 1.2604\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.9902 - val_loss: 1.4779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f060421ada0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 不同行为层用于训练与测试\n",
    "\n",
    "* 如 Dropout，BatchNormalization 层。\n",
    "* 下面的例子是一个在训练时添加高斯噪声的正则化层，但是测试时不执行任何操作（keras.layers.GaussianNoise）:\n",
    "* 主要是调整 call 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "        \n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 2.1858 - val_loss: 1.7280\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.0362 - val_loss: 1.0866\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.8010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8010250329971313"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
